import os
from openai import OpenAI
from dotenv import load_dotenv
from typing import List,Dict

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å°è£…ä¸€ä¸ªæ¨¡å‹ç±»
class HelloAgentsLLM:
    """
    LLMå®¢æˆ·ç«¯ï¼Œè°ƒç”¨å…¼å®¹OpenAIæ¥å£çš„æœåŠ¡
    è¿™é‡Œä½¿ç”¨çš„æ˜¯KIMIå¤§æ¨¡å‹
    """
    def __init__(self,model:str=None,apiKey:str=None,baseUrl:str=None,timeout:int=None):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯
        """
        self.model = model or os.getenv("LLM_MODEL_ID")
        apiKey = apiKey or os.getenv("LLM_API_KEY")
        baseUrl = baseUrl or os.getenv("LLM_BASE_URL")
        timeout = timeout or int(os.getenv("LLM_TIMEOUT",60))

        if not all([self.model,apiKey,baseUrl]):
            raise ValueError("æ¨¡å‹IDï¼ŒAPIå¯†é’¥å’Œè®¿é—®åœ°å€å¿…é¡»åœ¨.envæ–‡ä»¶ä¸­å®šä¹‰")
        
        self.client = OpenAI(api_key=apiKey,base_url=baseUrl)

    def think(self,messages:List[Dict[str,str]],temperature:float=0) -> str:
        """
        è°ƒç”¨å¤§æ¨¡å‹
        """
        print(f"ğŸ§  æ­£åœ¨è°ƒç”¨{self.model}æ¨¡å‹...")
        try:
            response = self.client.chat.completions.create(
                model = self.model,
                messages = messages,
                temperature = temperature,
                stream = True,
            )
            print("âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:")
            collected_content = []
            for chunk in response:
                content = chunk.choices[0].delta.content or ""
                print(content,end="",flush=True)
                collected_content.append(content)
            print() # æµå¼è¾“å‡ºåæ¢è¡Œ
            return "".join(collected_content)

        except Exception as e:
            print(f"âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None

if __name__ == "__main__":
    try:
        llmClient = HelloAgentsLLM()

        messages = [
            {"role":"system","content":"ä½ æ˜¯æˆ‘çš„ç§äººåŠ©æ‰‹"},
            {"role":"user","content":"ç¼–å†™ä¸€ä¸ªæ¯”è¾ƒå¤§å°çš„Pythonè„šæœ¬"}
        ]

        print("---è°ƒç”¨å¤§æ¨¡å‹---")

        response = llmClient.think(messages)
        if response:
            print("\n\n---å®Œæ•´çš„å“åº”å†…å®¹---")
            print(response)
    except Exception as e:
        print(f"å‡ºç°é”™è¯¯ï¼š{e}!")
